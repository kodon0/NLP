{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This workbook uses NMF for topic modelling for over 400,000 Quora questions. \n",
    "Aim here is to find out what the topics are. User needs to pick number of topics.\n",
    "K ODonnell 25/06/20 '''\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora = pd.read_csv('quora_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404289 entries, 0 to 404288\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   Question  404289 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(quora.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df has over 400k entries, so will use Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.99, min_df=1, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making document term matrix\n",
    "dtm = tfidf.fit_transform(quora['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NMF\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 40 topics (say)\n",
    "nmf_model = NMF(n_components=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=40, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a while...400k entries!\n",
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67533"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing length of feature names\n",
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shaggy\n",
      "m1\n",
      "ashrama\n",
      "sematary\n",
      "vadodara\n",
      "widowmaker\n",
      "ferraris\n",
      "battled\n",
      "nohara\n",
      "hurricanes\n"
     ]
    }
   ],
   "source": [
    "# Getting top 10 random words\n",
    "import random\n",
    "for i in range(10):\n",
    "    random_word_id = random.randint(0,len(tfidf.get_feature_names()))\n",
    "    print(tfidf.get_feature_names()[random_word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of topics\n",
    "len(nmf_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67533"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of words in a topic \n",
    "len(nmf_model.components_[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinlge topic '0'\n",
    "single_topic = nmf_model.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55244, 24528, 10891, 46231, 64387, 46244, 34721, 65132,  9740,\n",
       "        8601])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 word indeces for this topic 0:\n",
    "single_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of largest words\n",
    "top_word_indices = single_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site\n",
      "friend\n",
      "buy\n",
      "place\n",
      "visit\n",
      "places\n",
      "laptop\n",
      "ways\n",
      "book\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "# Top words for topic 0\n",
    "for index in top_word_indices:\n",
    "    print(tfidf.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 20 WORDS FOR TOPIC #0\n",
      "['songs', 'course', 'company', 'sites', 'digital', 'smartphone', 'marketing', 'institute', 'delhi', 'coaching', 'site', 'friend', 'buy', 'place', 'visit', 'places', 'laptop', 'ways', 'book', 'best']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #1\n",
      "['person', 'say', 'need', 'come', 'dream', 'says', 'affect', 'majors', 'universities', 'grads', 'recruit', 'looking', 'really', 'exist', 'compare', 'cost', 'long', 'feel', 'mean', 'does']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #2\n",
      "['message', 'change', 'views', 'needing', 'users', 'picture', 'write', 'topics', 'improvement', 'profile', 'follow', 'writer', 'asked', 'add', 'post', 'delete', 'answers', 'answer', 'question', 'quora']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #3\n",
      "['home', 'blog', 'dollars', 'faster', 'hair', 'video', 'interesting', 'million', 'fast', 'easy', 'great', '000', 'app', 'better', 'happy', 'month', 'youtube', 'friends', 'money', 'make']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #4\n",
      "['human', 'positions', 'departments', 'living', 'planets', 'decision', 'balance', 'biggest', 'change', 'earth', 'want', 'death', 'changed', 'live', 'moment', 'real', 'important', 'meaning', 'purpose', 'life']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #5\n",
      "['states', 'united', 'won', 'racist', 'elected', 'elections', 'usa', 'affect', 'students', 'wins', 'america', 'presidential', 'presidency', 'happen', 'vote', 'election', 'win', 'president', 'donald', 'trump']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #6\n",
      "['math', 'hack', 'chinese', 'data', 'marketing', 'speak', 'javascript', 'book', 'guitar', 'play', 'quickly', 'coding', 'languages', 'online', 'want', 'hacking', 'english', 'python', 'java', 'learn']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #7\n",
      "['gadgets', 'intelligent', 'exist', 'ask', 'chinese', 'god', 'want', 'care', 'black', 'white', 'say', 'earth', 'easily', 'blowing', 'mind', 'flat', 'hate', 'believe', 'don', 'people']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #8\n",
      "['affect', 'corruption', 'help', 'money', 'decision', 'rupees', '2000', 'modi', 'currency', 'economy', 'government', 'ban', 'banning', 'black', 'indian', 'rupee', 'rs', 'notes', '1000', '500']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #9\n",
      "['future', 'daniel', 'colleges', 'visit', 'ek', 'scope', 'company', 'demonetization', 'prime', 'reservation', 'minister', 'china', 'president', 'country', 'olympics', 'available', 'spotify', 'war', 'pakistan', 'india']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #10\n",
      "['health', 'differ', 'score', 'ideas', 'balance', 'idea', 'positions', 'departments', 'makes', 'near', 'california', 'ca', 'installation', 'solar', 'panel', 'provider', 'songs', 'bad', 'ways', 'good']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #11\n",
      "['child', 'taste', 'men', 'person', 'women', 'working', 'living', 'indian', 'guy', 'guys', 'corporate', 'different', 'companies', 'don', 'girls', 'culture', 'live', 'look', 'feel', 'like']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #12\n",
      "['enhance', 'specifically', 'words', 'vocabulary', 'ability', 'aspects', 'fluent', 'language', 'skill', 'spoken', 'ways', 'fluently', 'speak', 'communication', 'pronunciation', 'speaking', 'writing', 'skills', 'improve', 'english']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #13\n",
      "['whatsapp', 'psychopath', 'blocked', 'new', 'facts', 'going', 'loves', 'tools', 'guy', 'gadgets', 'cheating', 'really', 'employees', 'want', 'exist', 'likes', 'blowing', 'mind', 'don', 'know']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #14\n",
      "['losing', 'plan', 'loose', 'doing', 'belly', 'diet', 'help', 'healthy', 'month', 'exercise', 'pounds', 'reduce', 'quickly', 'loss', 'fast', 'fat', 'ways', 'gain', 'lose', 'weight']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #15\n",
      "['stop', 'manage', 'jobs', 'gifts', 'bring', 'invited', 'foreign', 'visitor', 'exist', 'long', 'visitors', 'real', 'favorite', 'spend', 'person', 'machine', 'home', 'possible', 'travel', 'time']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #16\n",
      "['meaning', 'story', 'possible', 'say', 'infatuation', 'man', 'girlfriend', 'marriage', 'doesn', 'tell', 'parents', 'falling', 'feel', 'friend', 'really', 'forget', 'true', 'person', 'fall', 'love']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #17\n",
      "['anger', 'milky', 'cheapest', 'gain', 'kill', 'stop', 'control', 'healthy', 'rid', 'reduce', 'easy', 'best', 'quickest', 'prepare', 'painless', 'commit', 'fastest', 'suicide', 'easiest', 'way']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #18\n",
      "['person', 'beautiful', 'win', 'ii', 'flat', 'going', 'imminent', 'likely', 'russia', 'live', 'coming', 'countries', 'place', 'pakistan', 'happen', 'end', 'country', 'iii', 'war', 'world']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #19\n",
      "['courses', 'shopping', 'save', 'invest', 'student', 'easiest', 'working', 'making', 'free', 'easily', 'investment', 'home', 'easy', 'internet', 'black', 'youtube', 'ways', 'earn', 'online', 'money']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #20\n",
      "['data', 'investment', 'startup', 'need', 'ideas', 'writing', 'small', 'idea', 'career', 'python', 'machine', 'company', 'exam', 'preparing', 'ias', 'preparation', 'want', 'learning', 'business', 'start']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #21\n",
      "['machine', 'sentences', 'basic', 'python', 'windows', 'main', 'company', 'culture', 'engineering', 'infatuation', 'end', 'web', 'scripting', 'java', 'chinese', 'software', 'data', 'computer', 'science', 'difference']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #22\n",
      "['old', 'followers', 'reset', 'number', 'log', 'private', 'bank', 'deleted', 'viewed', 'whatsapp', 'forgot', 'delete', 'recover', 'email', 'hack', 'gmail', 'password', 'facebook', 'instagram', 'account']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #23\n",
      "['15', '16', 'advice', '2000', 'upcoming', '13', 'york', 'years', 'prepare', 'recruit', 'majors', 'grads', 'looking', 'universities', 'resolutions', 'resolution', 'old', '2017', 'new', 'year']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #24\n",
      "['moon', 'significance', 'contrast', 'compare', 'somme', 'war', 'long', 'hitler', 'change', 'exist', 'god', 'bang', 'election', 'big', 'die', 'really', 'come', 'battle', 'win', 'did']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #25\n",
      "['girlfriend', 'gay', 'girls', 'enjoy', 'period', 'longer', 'oral', 'marriage', 'man', 'experience', 'woman', 'pregnant', 'anal', 'relationship', 'having', 'men', 'important', 'women', 'feel', 'sex']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #26\n",
      "['election', 'presidential', 'girls', 'indian', 'men', 'decision', 'win', 'caring', 'china', 'modi', 'earth', 'americans', 'flat', 'worrying', 'women', 'care', 'chinese', 'indians', 'stop', 'think']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #27\n",
      "['study', 'university', 'civil', 'electrical', 'college', 'career', 'student', 'tech', 'software', 'engineer', 'prepare', 'science', 'making', 'process', 'tips', 'computer', 'mechanical', 'interview', 'engineering', 'job']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #28\n",
      "['develop', 'word', 'machine', 'python', 'foreign', 'competitive', 'game', 'java', 'version', 'latest', 'keywords', 'beginners', 'scripting', 'beginner', 'computer', 'used', 'languages', 'learning', 'programming', 'language']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #29\n",
      "['heard', 'bad', 'happen', 'nice', 'craziest', 'regret', 'doing', 'die', 'weirdest', 'embarrassing', 'said', 'funniest', 'want', 'seen', 've', 'change', 'happened', 'worst', 'important', 'thing']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #30\n",
      "['days', 'visitors', 'universal', 'unexpected', 'healthy', 'notice', 'indians', 'die', 'bank', 'hours', 'bad', 'happen', 'period', 'eat', 'pregnant', 'new', 'employees', 'going', 'day', 'things']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #31\n",
      "['review', 'expected', 'elections', 'tv', 'sa', 'romantic', 'kvpy', '10', 'download', 'horror', 'favorite', 'election', 'presidential', 'bollywood', 'win', 'hollywood', 'watch', 'movie', '2016', 'movies']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #32\n",
      "['engineer', 'experience', 'want', 'companies', 'does', 'google', 'hard', 'company', 'home', 'employees', 'relationships', 'differ', 'really', 'positions', 'departments', 'balance', 'relationship', 'distance', 'long', 'work']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #33\n",
      "['free', 've', 'iit', 'self', 'jee', 'indian', 'study', 'beginners', 'gate', 'fiction', 'reading', 'learning', 'preparation', 'java', 'exam', 'prepare', 'favorite', 'book', 'read', 'books']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #34\n",
      "['crush', 'impress', 'mean', 'marry', 'talk', 'girlfriend', 'friends', 'really', 'indian', 'ask', 'boyfriend', 'date', 'want', 'old', 'tell', 'boy', 'friend', 'likes', 'guy', 'girl']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #35\n",
      "['answering', 'just', 'need', 'instead', 'internet', 'googling', 'marked', 'quora', 'search', 'needing', 'answers', 'answered', 'answer', 'improvement', 'interview', 'asked', 'easily', 'google', 'ask', 'questions']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['websites', 'seo', 'organic', 'commerce', 'promote', 'video', 'company', 'site', 'social', 'blog', 'cost', 'online', 'com', 'app', 'create', 'build', 'download', 'free', 'traffic', 'website']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #37\n",
      "['site', 'person', '25', '22', 'size', 'speed', 'skipping', 'penis', '21', 'old', 'iq', 'possible', 'years', '20', 'blog', 'age', 'ways', 'traffic', 'height', 'increase']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #38\n",
      "['grades', 'person', 'worse', 'health', 'plan', 'war', 'liar', 'choice', 'jail', 'debate', 'president', 'russia', 'hate', 'presidential', 'election', 'policy', 'vote', 'better', 'hillary', 'clinton']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #39\n",
      "['3g', 'track', 'support', 'whatsapp', 'sentence', 'cell', 'apps', 'card', 'jio', 'sim', 'using', 'google', 'app', 'mobile', 'buy', 'iphone', 'android', 'number', 'phone', 'use']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting top 20 words for each topic\n",
    "\n",
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 20 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attatch topic to original DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  Topic\n",
      "0  What is the step by step guide to invest in sh...      9\n",
      "1  What is the story of Kohinoor (Koh-i-Noor) Dia...     16\n",
      "2  How can I increase the speed of my internet co...     37\n",
      "3  Why am I mentally very lonely? How can I solve...      8\n",
      "4  Which one dissolve in water quikly sugar, salt...     39\n"
     ]
    }
   ],
   "source": [
    "print(quora.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
